{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f37f9c",
   "metadata": {},
   "source": [
    "### Christos Vlassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f5e8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the libriaries to use:\n",
    "import random\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f2c40f",
   "metadata": {},
   "source": [
    "# 1)  Import and pre-process the dataset with users"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e88f723",
   "metadata": {},
   "source": [
    "Before we use any programming language, we will clean the text files with the use of Linux. \n",
    "For the movies.txt:\n",
    "•\tI used these commands in Linux to clean the data. Firstly, I removed the unnecessary columns. This means I kept only the id column, the name of the movies and the published year. Then, I removed the years that were in parenthesis in the second column and piped the output to a new text file called ‘Main_movies_data’.\n",
    "awk -F'|' '{split($2, a, \" \"); n = length(a); gsub(/[()]/, \"\", a[n]); print $1\"|\"$2\"|\"a[n]}' movies.txt | awk -F'|' '{gsub(/ \\([0-9]{4}\\)/, \"\", $2); print $1\"|\"$2\"|\"$3}' > Main_movies_data\n",
    "•\tI created a new file with the name of the columns: \n",
    "echo \"movie_id|title|year_published\" > movie_titles.txt\n",
    "•\tFinaly, I merged the files using:\n",
    "cat Main_movies_data >> movie_titles.txt\n",
    "Now I have the titles for each column and I use this ‘|’ as delimiter. I renamed the txt file to Main_ movies using the UI. \n",
    "\n",
    "For the ratings.txt:\n",
    "•\tFirstly, I used this command to change the delimiter to | and create a new file:\n",
    "awk '{print $1\"|\"$2\"|\"$3\"|\"$4}' ratings.txt > ratings2   \n",
    "•\tThen I created a new file to create the column names:\n",
    "echo \"user_id|movie_id|rating|timestamp\" > rating_titles.txt\n",
    "•\tFinaly, I merged the files using:\n",
    "cat ratings2  >> rating_titles.txt\n",
    "Now I have the titles for each column and I use this ‘|’ as delimiter. I renamed the txt file to Main_ratings using the UI. \n",
    "\n",
    "For the users.txt:\n",
    "•\tI only created a new file to create the column names:\n",
    "echo \"user_id|age|gender|occupation|postal_code\" > user_titles.txt\n",
    "•\tI merged it with the data: \n",
    "cat users.txt >> user_titles.txt  \n",
    "I used the UI to rename the file to ‘Main_users’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc237c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the ratings data\n",
    "Main_ratings = pd.read_csv(\"C:\\\\Users\\\\vlass\\\\OneDrive\\\\Υπολογιστής\\\\Metaptyxiako\\\\3rd_Trimester\\\\Mining_Big_Dataset\\\\Project_1\\\\Movie Lens Dataset\\\\Main_ratings.txt\", sep=\"|\", header=0)\n",
    "\n",
    "# importing the users data\n",
    "Main_users = pd.read_csv(\"C:\\\\Users\\\\vlass\\\\OneDrive\\\\Υπολογιστής\\\\Metaptyxiako\\\\3rd_Trimester\\\\Mining_Big_Dataset\\\\Project_1\\\\Movie Lens Dataset\\\\Main_users.txt\", sep=\"|\", header=0)\n",
    "\n",
    "# importing the movies data\n",
    "Main_movies = pd.read_csv(\"C:\\\\Users\\\\vlass\\\\OneDrive\\\\Υπολογιστής\\\\Metaptyxiako\\\\3rd_Trimester\\\\Mining_Big_Dataset\\\\Project_1\\\\Movie Lens Dataset\\\\Main_movies.txt\", sep=\"|\", header=0,encoding='ISO-8859-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e10e963",
   "metadata": {},
   "source": [
    "# 2) Compute exact Jaccard similarity of users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b8652ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we loop throught the data frame and create a dictionary that will contain the sets.\n",
    "# each set represents a user_id of  and contains the movies that he has rated.\n",
    "user_movies = {}\n",
    "for index, row in Main_ratings.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    movie_id = row['movie_id']\n",
    "    if user_id not in user_movies:\n",
    "        user_movies[user_id] = set()  # Create a new set if this is a new user_id\n",
    "    user_movies[user_id].add(movie_id)  # Add the movie_id to the user's set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccd3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function that calculates the jaccard distance:\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1) + len(set2) - intersection\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7714d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list. each list represents a user_id and the sets contains the movie_ids that the users has rated:\n",
    "i = 1\n",
    "Main_sets = []\n",
    "while i <= len(user_movies):  \n",
    "    Main_sets.append(user_movies[i])\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "#### Note: Because it is a list, user 1 now is called user 0, user 2 is called user 1 e.t.c\n",
    "#### or, even better, user 1 is in position 0, user 2 in position 1 e.t.c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fb3625a",
   "metadata": {},
   "source": [
    "## Caclulating the Jaccard Similarity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29f51331",
   "metadata": {},
   "source": [
    "1. We will use the jaccard_similarity function that was created before.\n",
    "2. We will output only the pairs that have similarity greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ea62bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pairs that are similar are 197 600\n",
      "The Jaccard similarity between these pairs is 0.5\n",
      "\n",
      "The pairs that are similar are 197 826\n",
      "The Jaccard similarity between these pairs is 0.513\n",
      "\n",
      "The pairs that are similar are 328 788\n",
      "The Jaccard similarity between these pairs is 0.673\n",
      "\n",
      "The pairs that are similar are 408 898\n",
      "The Jaccard similarity between these pairs is 0.839\n",
      "\n",
      "The pairs that are similar are 451 489\n",
      "The Jaccard similarity between these pairs is 0.533\n",
      "\n",
      "The pairs that are similar are 489 587\n",
      "The Jaccard similarity between these pairs is 0.63\n",
      "\n",
      "The pairs that are similar are 554 764\n",
      "The Jaccard similarity between these pairs is 0.517\n",
      "\n",
      "The pairs that are similar are 600 826\n",
      "The Jaccard similarity between these pairs is 0.545\n",
      "\n",
      "The pairs that are similar are 674 879\n",
      "The Jaccard similarity between these pairs is 0.522\n",
      "\n",
      "The pairs that are similar are 800 879\n",
      "The Jaccard similarity between these pairs is 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = list()\n",
    "max_similarity = 0 \n",
    "for i, j in combinations(range(len(Main_sets)), 2):\n",
    "    set1 = Main_sets[i]\n",
    "    set2 = Main_sets[j]\n",
    "    similarity = jaccard_similarity(set1, set2)\n",
    "    similarity = round(similarity, 3) \n",
    "    if similarity > max_similarity:\n",
    "        max_similarity = similarity\n",
    "        max_pairs = (i+1,j+1)\n",
    "        max_common_movies = set1.intersection(set2)  \n",
    "    if similarity >= 0.5:\n",
    "        print(f\"The pairs that are similar are {i+1} {j+1}\")\n",
    "        print(f\"The Jaccard similarity between these pairs is {similarity}\\n\")\n",
    "        # i create the pairs that were found to have the same similarity\n",
    "        merged_value = str(i) + '-' + str(j)\n",
    "        y_true.append(merged_value) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72abd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets bring the name of the movies: \n",
    "merged_df = pd.merge(Main_movies, Main_ratings, on='movie_id')\n",
    "\n",
    "# lets keep only the relevant rows: \n",
    "selected_rows = merged_df[merged_df['movie_id'].isin(max_common_movies)]\n",
    "\n",
    "# select the movie titles that are similar for both:\n",
    "man_common_movie_names = selected_rows['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c69d1d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar pairs are: (408, 898)\n",
      "With a max similarity of 0.839\n",
      "And their common movies are ['Kolya' 'Contact' 'Gattaca' 'Starship Troopers' 'Good Will Hunting'\n",
      " 'English Patient, The' 'Scream' 'Air Force One' 'L.A. Confidential'\n",
      " 'Rainmaker, The' 'Midnight in the Garden of Good and Evil' 'Titanic'\n",
      " 'Apt Pupil' 'Everyone Says I Love You' 'Lost Highway' 'Cop Land'\n",
      " 'Conspiracy Theory' 'U Turn' 'Wag the Dog' 'Spawn' 'Mouse Hunt'\n",
      " 'Rocket Man' 'Jackal, The' 'Saint, The' 'Tomorrow Never Dies'\n",
      " 'Indian Summer']\n"
     ]
    }
   ],
   "source": [
    "# We output most similar pair of users, with their common movies and similarity score:\n",
    "print(f'The most similar pairs are: {max_pairs}')\n",
    "print(f'With a max similarity of {max_similarity}')\n",
    "print(f'And their common movies are {man_common_movie_names}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f6af912",
   "metadata": {},
   "source": [
    "# 3) Compute similarity using Min-hash signatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6572b7f",
   "metadata": {},
   "source": [
    "### 3.A) Using 50 hash functions for the evaluation of Min-hashing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09224fe6",
   "metadata": {},
   "source": [
    "1st i create a function for finding the min signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cb865af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hash function\n",
    "def compute_min_value(a, value, b, R, min_value):\n",
    "    # Compute new_value\n",
    "    new_value = (a * value + b) % R\n",
    "    # Check if new_value is less than min_value\n",
    "    if new_value < min_value:\n",
    "        min_value = new_value\n",
    "    return min_value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ace4a12",
   "metadata": {},
   "source": [
    "The logic for the loops:\n",
    "We find for every user for all the hash function the min signatures and import them to a new list called list_of_hashes.\n",
    "This list will have the min-signatures of all the hash functions. We use a seed to change the hash functions but on the same time we have the same hash functions accross all the users.\n",
    "\n",
    "We append to the list_of_5_dif_functions the lists that contain the min signatures for each run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaa108e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 199999\n",
    "list_of_5_dif_functions = list()\n",
    "\n",
    "list_of_seeds = [50,100,250,350,450]\n",
    "# for 5 different runs\n",
    "for y in list_of_seeds:\n",
    "    list_of_hashes = list()\n",
    "    # for every user\n",
    "    for sets in Main_sets:\n",
    "        hash_list = list()\n",
    "        # for every hash function\n",
    "        for i in range(1,51): ## change this to 51, 101 OR 201 for more hash functions!\n",
    "            random.seed(i+y) # call fixed seed. That way we will have the same a and b for all the same hash function accross users\n",
    "            a  = random.randint(1000, 10990) # create a variable\n",
    "            b  = random.randint(11000, 20000) # create b variable\n",
    "            min_value = 200000\n",
    "            # for every movie of the user \n",
    "            # calculate the min signature \n",
    "            for value in sets:\n",
    "                min_value = compute_min_value(a, value, b, R, min_value)\n",
    "            hash_list.append(min_value)\n",
    "        list_of_hashes.append(hash_list)  \n",
    "    list_of_5_dif_functions.append(list_of_hashes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d69cc2a",
   "metadata": {},
   "source": [
    "Now that we have the lists with the min signatures for all the users we find the similarity with the use of the min signatures. At the same time we find the pairs that are similar according to the min signature method. This is information is contained in the y_pred list. We will only output the users with similarity greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd1b8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run the users 7 and 194 have similarity equal to: 0.5\n",
      "For the 1st run the users 7 and 234 have similarity equal to: 0.54\n",
      "For the 1st run the users 7 and 311 have similarity equal to: 0.5\n",
      "For the 1st run the users 7 and 326 have similarity equal to: 0.52\n",
      "For the 1st run the users 7 and 650 have similarity equal to: 0.56\n",
      "For the 1st run the users 7 and 788 have similarity equal to: 0.5\n",
      "For the 1st run the users 7 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 33 and 616 have similarity equal to: 0.5\n",
      "For the 1st run the users 35 and 362 have similarity equal to: 0.5\n",
      "For the 1st run the users 37 and 217 have similarity equal to: 0.54\n",
      "For the 1st run the users 40 and 915 have similarity equal to: 0.56\n",
      "For the 1st run the users 42 and 280 have similarity equal to: 0.5\n",
      "For the 1st run the users 42 and 378 have similarity equal to: 0.5\n",
      "For the 1st run the users 59 and 429 have similarity equal to: 0.5\n",
      "For the 1st run the users 59 and 533 have similarity equal to: 0.5\n",
      "For the 1st run the users 59 and 650 have similarity equal to: 0.5\n",
      "For the 1st run the users 59 and 716 have similarity equal to: 0.62\n",
      "For the 1st run the users 64 and 457 have similarity equal to: 0.54\n",
      "For the 1st run the users 64 and 916 have similarity equal to: 0.52\n",
      "For the 1st run the users 72 and 339 have similarity equal to: 0.5\n",
      "For the 1st run the users 92 and 222 have similarity equal to: 0.54\n",
      "For the 1st run the users 92 and 276 have similarity equal to: 0.62\n",
      "For the 1st run the users 92 and 303 have similarity equal to: 0.54\n",
      "For the 1st run the users 92 and 374 have similarity equal to: 0.52\n",
      "For the 1st run the users 92 and 435 have similarity equal to: 0.52\n",
      "For the 1st run the users 92 and 497 have similarity equal to: 0.5\n",
      "For the 1st run the users 92 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 92 and 727 have similarity equal to: 0.52\n",
      "For the 1st run the users 92 and 864 have similarity equal to: 0.5\n",
      "For the 1st run the users 94 and 194 have similarity equal to: 0.52\n",
      "For the 1st run the users 94 and 378 have similarity equal to: 0.54\n",
      "For the 1st run the users 94 and 457 have similarity equal to: 0.52\n",
      "For the 1st run the users 94 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 94 and 864 have similarity equal to: 0.54\n",
      "For the 1st run the users 94 and 916 have similarity equal to: 0.54\n",
      "For the 1st run the users 95 and 450 have similarity equal to: 0.5\n",
      "For the 1st run the users 95 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 109 and 200 have similarity equal to: 0.54\n",
      "For the 1st run the users 109 and 276 have similarity equal to: 0.5\n",
      "For the 1st run the users 109 and 301 have similarity equal to: 0.54\n",
      "For the 1st run the users 109 and 457 have similarity equal to: 0.54\n",
      "For the 1st run the users 109 and 653 have similarity equal to: 0.52\n",
      "For the 1st run the users 109 and 805 have similarity equal to: 0.52\n",
      "For the 1st run the users 111 and 866 have similarity equal to: 0.5\n",
      "For the 1st run the users 112 and 772 have similarity equal to: 0.54\n",
      "For the 1st run the users 130 and 276 have similarity equal to: 0.52\n",
      "For the 1st run the users 133 and 166 have similarity equal to: 0.56\n",
      "For the 1st run the users 140 and 155 have similarity equal to: 0.5\n",
      "For the 1st run the users 140 and 364 have similarity equal to: 0.5\n",
      "For the 1st run the users 141 and 938 have similarity equal to: 0.5\n",
      "For the 1st run the users 143 and 856 have similarity equal to: 0.5\n",
      "For the 1st run the users 151 and 406 have similarity equal to: 0.52\n",
      "For the 1st run the users 151 and 474 have similarity equal to: 0.52\n",
      "For the 1st run the users 151 and 716 have similarity equal to: 0.5\n",
      "For the 1st run the users 151 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 168 and 938 have similarity equal to: 0.5\n",
      "For the 1st run the users 194 and 311 have similarity equal to: 0.56\n",
      "For the 1st run the users 194 and 378 have similarity equal to: 0.52\n",
      "For the 1st run the users 194 and 457 have similarity equal to: 0.56\n",
      "For the 1st run the users 194 and 846 have similarity equal to: 0.52\n",
      "For the 1st run the users 194 and 889 have similarity equal to: 0.5\n",
      "For the 1st run the users 197 and 600 have similarity equal to: 0.6\n",
      "For the 1st run the users 197 and 826 have similarity equal to: 0.72\n",
      "For the 1st run the users 200 and 301 have similarity equal to: 0.56\n",
      "For the 1st run the users 234 and 932 have similarity equal to: 0.56\n",
      "For the 1st run the users 241 and 920 have similarity equal to: 0.52\n",
      "For the 1st run the users 256 and 332 have similarity equal to: 0.52\n",
      "For the 1st run the users 258 and 589 have similarity equal to: 0.52\n",
      "For the 1st run the users 268 and 660 have similarity equal to: 0.5\n",
      "For the 1st run the users 271 and 379 have similarity equal to: 0.52\n",
      "For the 1st run the users 276 and 303 have similarity equal to: 0.5\n",
      "For the 1st run the users 276 and 435 have similarity equal to: 0.56\n",
      "For the 1st run the users 276 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 276 and 727 have similarity equal to: 0.5\n",
      "For the 1st run the users 276 and 864 have similarity equal to: 0.52\n",
      "For the 1st run the users 281 and 589 have similarity equal to: 0.52\n",
      "For the 1st run the users 293 and 303 have similarity equal to: 0.5\n",
      "For the 1st run the users 293 and 378 have similarity equal to: 0.52\n",
      "For the 1st run the users 293 and 450 have similarity equal to: 0.5\n",
      "For the 1st run the users 293 and 653 have similarity equal to: 0.5\n",
      "For the 1st run the users 293 and 682 have similarity equal to: 0.52\n",
      "For the 1st run the users 293 and 846 have similarity equal to: 0.52\n",
      "For the 1st run the users 301 and 435 have similarity equal to: 0.5\n",
      "For the 1st run the users 301 and 457 have similarity equal to: 0.56\n",
      "For the 1st run the users 303 and 435 have similarity equal to: 0.54\n",
      "For the 1st run the users 303 and 497 have similarity equal to: 0.56\n",
      "For the 1st run the users 303 and 727 have similarity equal to: 0.52\n",
      "For the 1st run the users 308 and 429 have similarity equal to: 0.54\n",
      "For the 1st run the users 308 and 892 have similarity equal to: 0.52\n",
      "For the 1st run the users 311 and 313 have similarity equal to: 0.5\n",
      "For the 1st run the users 311 and 326 have similarity equal to: 0.5\n",
      "For the 1st run the users 311 and 378 have similarity equal to: 0.5\n",
      "For the 1st run the users 311 and 450 have similarity equal to: 0.52\n",
      "For the 1st run the users 311 and 457 have similarity equal to: 0.5\n",
      "For the 1st run the users 311 and 650 have similarity equal to: 0.52\n",
      "For the 1st run the users 311 and 846 have similarity equal to: 0.62\n",
      "For the 1st run the users 313 and 846 have similarity equal to: 0.56\n",
      "For the 1st run the users 326 and 815 have similarity equal to: 0.56\n",
      "For the 1st run the users 326 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 328 and 788 have similarity equal to: 0.68\n",
      "For the 1st run the users 339 and 846 have similarity equal to: 0.54\n",
      "For the 1st run the users 350 and 890 have similarity equal to: 0.52\n",
      "For the 1st run the users 356 and 856 have similarity equal to: 0.54\n",
      "For the 1st run the users 362 and 772 have similarity equal to: 0.56\n",
      "For the 1st run the users 373 and 889 have similarity equal to: 0.5\n",
      "For the 1st run the users 373 and 933 have similarity equal to: 0.5\n",
      "For the 1st run the users 378 and 457 have similarity equal to: 0.54\n",
      "For the 1st run the users 378 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 378 and 846 have similarity equal to: 0.56\n",
      "For the 1st run the users 378 and 896 have similarity equal to: 0.52\n",
      "For the 1st run the users 394 and 472 have similarity equal to: 0.5\n",
      "For the 1st run the users 399 and 886 have similarity equal to: 0.5\n",
      "For the 1st run the users 399 and 943 have similarity equal to: 0.5\n",
      "For the 1st run the users 405 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 406 and 561 have similarity equal to: 0.52\n",
      "For the 1st run the users 406 and 716 have similarity equal to: 0.54\n",
      "For the 1st run the users 406 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 408 and 898 have similarity equal to: 0.78\n",
      "For the 1st run the users 416 and 450 have similarity equal to: 0.58\n",
      "For the 1st run the users 417 and 435 have similarity equal to: 0.54\n",
      "For the 1st run the users 428 and 587 have similarity equal to: 0.5\n",
      "For the 1st run the users 429 and 561 have similarity equal to: 0.5\n",
      "For the 1st run the users 431 and 589 have similarity equal to: 0.52\n",
      "For the 1st run the users 435 and 497 have similarity equal to: 0.5\n",
      "For the 1st run the users 435 and 682 have similarity equal to: 0.52\n",
      "For the 1st run the users 435 and 864 have similarity equal to: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run the users 446 and 853 have similarity equal to: 0.5\n",
      "For the 1st run the users 450 and 474 have similarity equal to: 0.52\n",
      "For the 1st run the users 450 and 524 have similarity equal to: 0.5\n",
      "For the 1st run the users 450 and 846 have similarity equal to: 0.52\n",
      "For the 1st run the users 451 and 489 have similarity equal to: 0.5\n",
      "For the 1st run the users 451 and 587 have similarity equal to: 0.5\n",
      "For the 1st run the users 457 and 586 have similarity equal to: 0.54\n",
      "For the 1st run the users 457 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 457 and 864 have similarity equal to: 0.58\n",
      "For the 1st run the users 457 and 916 have similarity equal to: 0.5\n",
      "For the 1st run the users 457 and 943 have similarity equal to: 0.5\n",
      "For the 1st run the users 484 and 586 have similarity equal to: 0.52\n",
      "For the 1st run the users 485 and 547 have similarity equal to: 0.52\n",
      "For the 1st run the users 489 and 587 have similarity equal to: 0.64\n",
      "For the 1st run the users 489 and 724 have similarity equal to: 0.56\n",
      "For the 1st run the users 495 and 650 have similarity equal to: 0.52\n",
      "For the 1st run the users 497 and 727 have similarity equal to: 0.52\n",
      "For the 1st run the users 515 and 784 have similarity equal to: 0.52\n",
      "For the 1st run the users 529 and 853 have similarity equal to: 0.52\n",
      "For the 1st run the users 535 and 840 have similarity equal to: 0.5\n",
      "For the 1st run the users 544 and 784 have similarity equal to: 0.5\n",
      "For the 1st run the users 547 and 740 have similarity equal to: 0.5\n",
      "For the 1st run the users 551 and 682 have similarity equal to: 0.58\n",
      "For the 1st run the users 554 and 764 have similarity equal to: 0.56\n",
      "For the 1st run the users 561 and 650 have similarity equal to: 0.5\n",
      "For the 1st run the users 561 and 846 have similarity equal to: 0.54\n",
      "For the 1st run the users 587 and 724 have similarity equal to: 0.58\n",
      "For the 1st run the users 589 and 772 have similarity equal to: 0.5\n",
      "For the 1st run the users 589 and 856 have similarity equal to: 0.5\n",
      "For the 1st run the users 600 and 826 have similarity equal to: 0.62\n",
      "For the 1st run the users 650 and 653 have similarity equal to: 0.52\n",
      "For the 1st run the users 650 and 804 have similarity equal to: 0.5\n",
      "For the 1st run the users 650 and 881 have similarity equal to: 0.52\n",
      "For the 1st run the users 653 and 682 have similarity equal to: 0.52\n",
      "For the 1st run the users 673 and 784 have similarity equal to: 0.52\n",
      "For the 1st run the users 674 and 879 have similarity equal to: 0.5\n",
      "For the 1st run the users 682 and 727 have similarity equal to: 0.52\n",
      "For the 1st run the users 694 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 724 and 863 have similarity equal to: 0.56\n",
      "For the 1st run the users 727 and 864 have similarity equal to: 0.5\n",
      "For the 1st run the users 740 and 791 have similarity equal to: 0.52\n",
      "For the 1st run the users 752 and 863 have similarity equal to: 0.5\n",
      "For the 1st run the users 772 and 784 have similarity equal to: 0.5\n",
      "For the 1st run the users 772 and 816 have similarity equal to: 0.52\n",
      "For the 1st run the users 772 and 853 have similarity equal to: 0.5\n",
      "For the 1st run the users 772 and 856 have similarity equal to: 0.54\n",
      "For the 1st run the users 784 and 920 have similarity equal to: 0.5\n",
      "For the 1st run the users 800 and 879 have similarity equal to: 0.56\n",
      "For the 1st run the users 815 and 843 have similarity equal to: 0.5\n",
      "For the 1st run the users 815 and 892 have similarity equal to: 0.52\n",
      "For the 1st run the users 846 and 889 have similarity equal to: 0.52\n",
      "For the 1st run the users 846 and 896 have similarity equal to: 0.54\n"
     ]
    }
   ],
   "source": [
    "# calculate the y_pred. This will be used to calculate the False positive and False negative.\n",
    "# We do this for all functions.\n",
    "y_pred = list()\n",
    "y_pred_Second_function = list() \n",
    "y_pred_Third_function = list() \n",
    "y_pred_Fourth_function = list() \n",
    "y_pred_Fifth_function = list() \n",
    "for indexer in range(0,5):\n",
    "    # i and j moves throught the lists. For all the combinations of lists!\n",
    "    # values moves the values of the lists\n",
    "    for i, j in combinations(range(len(list_of_5_dif_functions[indexer])), 2): \n",
    "        counter = 0 \n",
    "        total_counter = 0 \n",
    "        ratio = 0\n",
    "        # when this loop ends, i will have passed thought the first combination of lists:\n",
    "        for values in range(len(list_of_5_dif_functions[indexer][i])): \n",
    "            total_counter = total_counter + 1\n",
    "            if list_of_5_dif_functions[indexer][i][values] == list_of_5_dif_functions[indexer][j][values]: \n",
    "                counter = counter + 1\n",
    "        ratio = counter/total_counter\n",
    "        ratio = round(ratio,2)\n",
    "        if ratio>= 0.5:\n",
    "            # i create the pairs that were found to have the same similarity\n",
    "            ## indexer enumerates throught the different lists. Each of the list is calculated with a different hash function\n",
    "            if indexer == 0:\n",
    "                merged_value = str(i) + '-' + str(j)\n",
    "                y_pred.append(merged_value)\n",
    "                print(f'For the 1st run the users {i+1} and {j+1} have similarity equal to: {ratio}')\n",
    "            elif indexer == 1: \n",
    "                merged_value_Second_function = str(i) + '-' + str(j) \n",
    "                y_pred_Second_function.append(merged_value_Second_function) \n",
    "            elif indexer == 2:\n",
    "                merged_value_Third_function = str(i) + '-' + str(j) \n",
    "                y_pred_Third_function.append(merged_value_Third_function) \n",
    "            elif indexer == 3:\n",
    "                merged_value_Fourth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fourth_function.append(merged_value_Fourth_function) \n",
    "            else:\n",
    "                merged_value_Fifth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fifth_function.append(merged_value_Fifth_function) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3eb1869",
   "metadata": {},
   "source": [
    "Now its time to calculate the False Positives and False Negatives. We have 2 lists in our disposal. The y_true which contains the pairs of users that were found similar according to the Jacard similarity (>=0.5). We also have the y_pred which contains the pairs of users that were found similar according to the min signature method (>=0.5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64f4ee02",
   "metadata": {},
   "source": [
    "The logic: We find the True positives and from there we find the false positives and false negatives:\n",
    "\n",
    "True positives: are the values between the 2 lists that are equal. The pair exists in both Lists.\n",
    "False positives: The pair will be found in Hash but not in Jaccard. \n",
    "False negatives: The pair will not  be found in Hash but will be found in Jaccard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab866a5",
   "metadata": {},
   "source": [
    "The following code find the True positives and later we compute the false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad6f12d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run we found 168 false positives and 0 false negatives\n",
      "For 5 runs we found an average of 169.2 false positives and 1.2 false negatives\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "true_positives_Second_f = 0\n",
    "true_positives_Third_f = 0\n",
    "true_positives_Fourth_f = 0\n",
    "true_positives_Fifth_f = 0\n",
    "\n",
    "positive_predictions = len(y_pred)\n",
    "positve_actual = len(y_true)\n",
    "# for the values of the 'true' list\n",
    "for pairs_true in range(len(y_true)):\n",
    "    # for the values of the 'pred' list\n",
    "    for pairs_pred in range(len(y_pred)):\n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred[pairs_pred]:\n",
    "            true_positives = true_positives + 1\n",
    "    for pairs_pred in range(len(y_pred_Second_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Second_function[pairs_pred]:\n",
    "            true_positives_Second_f = true_positives_Second_f + 1         \n",
    "    for pairs_pred in range(len(y_pred_Third_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Third_function[pairs_pred]:\n",
    "            true_positives_Third_f = true_positives_Third_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fourth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fourth_function[pairs_pred]:\n",
    "            true_positives_Fourth_f = true_positives_Fourth_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fifth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fifth_function[pairs_pred]:\n",
    "            true_positives_Fifth_f = true_positives_Fifth_f + 1 \n",
    "    \n",
    "    \n",
    "    \n",
    "               \n",
    "# calculating the False Positives:\n",
    "false_positives = positive_predictions - true_positives \n",
    "false_positives_Second_Function = positive_predictions - true_positives_Second_f\n",
    "false_positives_Third_Function = positive_predictions - true_positives_Third_f\n",
    "false_positives_Fourth_Function = positive_predictions - true_positives_Fourth_f\n",
    "false_positives_Fifth_Function = positive_predictions - true_positives_Fifth_f\n",
    "\n",
    "false_positives_avg = (false_positives+false_positives_Second_Function+false_positives_Third_Function+false_positives_Fourth_Function+false_positives_Fifth_Function)/5\n",
    "\n",
    "# calculating the False Negatives:\n",
    "false_negatives = positve_actual - true_positives \n",
    "false_negatives_Second_Function = positve_actual - true_positives_Second_f \n",
    "false_negatives_Third_Function = positve_actual - true_positives_Third_f \n",
    "false_negatives_Fourth_Function = positve_actual - true_positives_Fourth_f \n",
    "false_negatives_Fifth_Function = positve_actual - true_positives_Fifth_f \n",
    "\n",
    "false_negatives_avg = (false_negatives+false_negatives_Second_Function+false_negatives_Third_Function+false_negatives_Fourth_Function+false_negatives_Fifth_Function)/5\n",
    "\n",
    "print(f'For the 1st run we found {false_positives} false positives and {false_negatives} false negatives')\n",
    "print(f'For 5 runs we found an average of {false_positives_avg} false positives and {false_negatives_avg} false negatives')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ee8c9a",
   "metadata": {},
   "source": [
    "We will do the same thing for 100 and 200 hash functions. I will not comment on these since we use exactly the same code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6d95b4e",
   "metadata": {},
   "source": [
    "### 3.B) Using 100 hash functions for the evaluation of Min-hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed87212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 199999\n",
    "# all the following 'list_of_hashes...' contain for each function the min signatures\n",
    "list_of_5_dif_functions = list()\n",
    "\n",
    "list_of_seeds = [50,100,250,350,450]\n",
    "# for 5 different runs\n",
    "for y in list_of_seeds:\n",
    "    list_of_hashes = list()\n",
    "    # for every user\n",
    "    for sets in Main_sets:\n",
    "        hash_list = list()\n",
    "        # for every hash function\n",
    "        for i in range(1,101): ## change this to 51, 101 OR 201 for more hash functions!\n",
    "            random.seed(i+y) # call fixed seed. That way we will have the same a and b for all the same hash function accross users\n",
    "            a  = random.randint(1000, 10990) # create a variable\n",
    "            b  = random.randint(11000, 20000) # create b variable\n",
    "            min_value = 200000\n",
    "            # for every movie of the user \n",
    "            # calculate the min signature \n",
    "            for value in sets:\n",
    "                min_value = compute_min_value(a, value, b, R, min_value)\n",
    "            hash_list.append(min_value)\n",
    "        list_of_hashes.append(hash_list)  \n",
    "    list_of_5_dif_functions.append(list_of_hashes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67550622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run the users 7 and 650 have similarity equal to: 0.51\n",
      "For the 1st run the users 18 and 234 have similarity equal to: 0.5\n",
      "For the 1st run the users 59 and 308 have similarity equal to: 0.5\n",
      "For the 1st run the users 92 and 276 have similarity equal to: 0.55\n",
      "For the 1st run the users 92 and 457 have similarity equal to: 0.5\n",
      "For the 1st run the users 94 and 682 have similarity equal to: 0.53\n",
      "For the 1st run the users 94 and 916 have similarity equal to: 0.52\n",
      "For the 1st run the users 112 and 772 have similarity equal to: 0.57\n",
      "For the 1st run the users 130 and 276 have similarity equal to: 0.54\n",
      "For the 1st run the users 133 and 166 have similarity equal to: 0.52\n",
      "For the 1st run the users 140 and 155 have similarity equal to: 0.53\n",
      "For the 1st run the users 151 and 474 have similarity equal to: 0.51\n",
      "For the 1st run the users 194 and 892 have similarity equal to: 0.5\n",
      "For the 1st run the users 197 and 600 have similarity equal to: 0.59\n",
      "For the 1st run the users 197 and 826 have similarity equal to: 0.68\n",
      "For the 1st run the users 222 and 378 have similarity equal to: 0.5\n",
      "For the 1st run the users 222 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 229 and 410 have similarity equal to: 0.51\n",
      "For the 1st run the users 234 and 932 have similarity equal to: 0.51\n",
      "For the 1st run the users 276 and 303 have similarity equal to: 0.53\n",
      "For the 1st run the users 276 and 727 have similarity equal to: 0.5\n",
      "For the 1st run the users 303 and 497 have similarity equal to: 0.52\n",
      "For the 1st run the users 308 and 429 have similarity equal to: 0.52\n",
      "For the 1st run the users 311 and 846 have similarity equal to: 0.52\n",
      "For the 1st run the users 326 and 815 have similarity equal to: 0.52\n",
      "For the 1st run the users 326 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 328 and 788 have similarity equal to: 0.66\n",
      "For the 1st run the users 356 and 856 have similarity equal to: 0.62\n",
      "For the 1st run the users 362 and 772 have similarity equal to: 0.53\n",
      "For the 1st run the users 408 and 898 have similarity equal to: 0.84\n",
      "For the 1st run the users 416 and 450 have similarity equal to: 0.57\n",
      "For the 1st run the users 435 and 551 have similarity equal to: 0.5\n",
      "For the 1st run the users 435 and 682 have similarity equal to: 0.5\n",
      "For the 1st run the users 446 and 853 have similarity equal to: 0.51\n",
      "For the 1st run the users 451 and 489 have similarity equal to: 0.56\n",
      "For the 1st run the users 451 and 587 have similarity equal to: 0.51\n",
      "For the 1st run the users 457 and 864 have similarity equal to: 0.52\n",
      "For the 1st run the users 474 and 846 have similarity equal to: 0.5\n",
      "For the 1st run the users 489 and 587 have similarity equal to: 0.65\n",
      "For the 1st run the users 489 and 724 have similarity equal to: 0.51\n",
      "For the 1st run the users 515 and 673 have similarity equal to: 0.5\n",
      "For the 1st run the users 551 and 682 have similarity equal to: 0.56\n",
      "For the 1st run the users 554 and 764 have similarity equal to: 0.53\n",
      "For the 1st run the users 574 and 784 have similarity equal to: 0.51\n",
      "For the 1st run the users 600 and 826 have similarity equal to: 0.58\n",
      "For the 1st run the users 673 and 784 have similarity equal to: 0.5\n",
      "For the 1st run the users 682 and 880 have similarity equal to: 0.5\n",
      "For the 1st run the users 683 and 863 have similarity equal to: 0.5\n",
      "For the 1st run the users 724 and 863 have similarity equal to: 0.51\n",
      "For the 1st run the users 752 and 863 have similarity equal to: 0.58\n",
      "For the 1st run the users 772 and 856 have similarity equal to: 0.5\n",
      "For the 1st run the users 800 and 879 have similarity equal to: 0.5\n"
     ]
    }
   ],
   "source": [
    "# calculate the y_pred. This will be used to calculate the False positive and False negative.\n",
    "# We do this for all functions.\n",
    "y_pred = list()\n",
    "y_pred_Second_function = list() \n",
    "y_pred_Third_function = list() \n",
    "y_pred_Fourth_function = list() \n",
    "y_pred_Fifth_function = list() \n",
    "for indexer in range(0,5):\n",
    "    # i and j moves throught the lists. For all the combinations of lists!\n",
    "    # values moves the values of the lists\n",
    "    for i, j in combinations(range(len(list_of_5_dif_functions[indexer])), 2): \n",
    "        counter = 0 \n",
    "        total_counter = 0 \n",
    "        ratio = 0\n",
    "        # when this loop ends, i will have passed thought the first combination of lists:\n",
    "        for values in range(len(list_of_5_dif_functions[indexer][i])): \n",
    "            total_counter = total_counter + 1\n",
    "            if list_of_5_dif_functions[indexer][i][values] == list_of_5_dif_functions[indexer][j][values]: \n",
    "                counter = counter + 1\n",
    "        ratio = counter/total_counter\n",
    "        ratio = round(ratio,2)\n",
    "        if ratio>= 0.5:\n",
    "            # i create the pairs that were found to have the same similarity\n",
    "            ## indexer enumerates throught the different lists. Each of the list is calculated with a different hash function\n",
    "            if indexer == 0:\n",
    "                merged_value = str(i) + '-' + str(j)\n",
    "                y_pred.append(merged_value)\n",
    "                print(f'For the 1st run the users {i+1} and {j+1} have similarity equal to: {ratio}')\n",
    "            elif indexer == 1: \n",
    "                merged_value_Second_function = str(i) + '-' + str(j) \n",
    "                y_pred_Second_function.append(merged_value_Second_function) \n",
    "            elif indexer == 2:\n",
    "                merged_value_Third_function = str(i) + '-' + str(j) \n",
    "                y_pred_Third_function.append(merged_value_Third_function) \n",
    "            elif indexer == 3:\n",
    "                merged_value_Fourth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fourth_function.append(merged_value_Fourth_function) \n",
    "            else:\n",
    "                merged_value_Fifth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fifth_function.append(merged_value_Fifth_function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1eb45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run we found 43 false positives and 1 false negatives\n",
      "For 5 runs we found an average of 44.2 false positives and 2.2 false negatives\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "true_positives_Second_f = 0\n",
    "true_positives_Third_f = 0\n",
    "true_positives_Fourth_f = 0\n",
    "true_positives_Fifth_f = 0\n",
    "\n",
    "positive_predictions = len(y_pred)\n",
    "positve_actual = len(y_true)\n",
    "# for the values of the 'true' list\n",
    "for pairs_true in range(len(y_true)):\n",
    "    # for the values of the 'pred' list\n",
    "    for pairs_pred in range(len(y_pred)):\n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred[pairs_pred]:\n",
    "            true_positives = true_positives + 1\n",
    "    for pairs_pred in range(len(y_pred_Second_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Second_function[pairs_pred]:\n",
    "            true_positives_Second_f = true_positives_Second_f + 1         \n",
    "    for pairs_pred in range(len(y_pred_Third_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Third_function[pairs_pred]:\n",
    "            true_positives_Third_f = true_positives_Third_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fourth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fourth_function[pairs_pred]:\n",
    "            true_positives_Fourth_f = true_positives_Fourth_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fifth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fifth_function[pairs_pred]:\n",
    "            true_positives_Fifth_f = true_positives_Fifth_f + 1 \n",
    "    \n",
    "    \n",
    "    \n",
    "               \n",
    "# calculating the False Positives:\n",
    "false_positives = positive_predictions - true_positives \n",
    "false_positives_Second_Function = positive_predictions - true_positives_Second_f\n",
    "false_positives_Third_Function = positive_predictions - true_positives_Third_f\n",
    "false_positives_Fourth_Function = positive_predictions - true_positives_Fourth_f\n",
    "false_positives_Fifth_Function = positive_predictions - true_positives_Fifth_f\n",
    "\n",
    "false_positives_avg = (false_positives+false_positives_Second_Function+false_positives_Third_Function+false_positives_Fourth_Function+false_positives_Fifth_Function)/5\n",
    "\n",
    "# calculating the False Negatives:\n",
    "false_negatives = positve_actual - true_positives \n",
    "false_negatives_Second_Function = positve_actual - true_positives_Second_f \n",
    "false_negatives_Third_Function = positve_actual - true_positives_Third_f \n",
    "false_negatives_Fourth_Function = positve_actual - true_positives_Fourth_f \n",
    "false_negatives_Fifth_Function = positve_actual - true_positives_Fifth_f \n",
    "\n",
    "false_negatives_avg = (false_negatives+false_negatives_Second_Function+false_negatives_Third_Function+false_negatives_Fourth_Function+false_negatives_Fifth_Function)/5\n",
    "\n",
    "print(f'For the 1st run we found {false_positives} false positives and {false_negatives} false negatives')\n",
    "print(f'For 5 runs we found an average of {false_positives_avg} false positives and {false_negatives_avg} false negatives')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc53c659",
   "metadata": {},
   "source": [
    "### 3.C) Using 200 hash functions for the evaluation of Min-hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9155db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 199999\n",
    "# all the following 'list_of_hashes...' contain for each function the min signatures\n",
    "list_of_5_dif_functions = list()\n",
    "\n",
    "list_of_seeds = [50,100,250,350,450]\n",
    "# for 5 different runs\n",
    "for y in list_of_seeds:\n",
    "    list_of_hashes = list()\n",
    "    # for every user\n",
    "    for sets in Main_sets:\n",
    "        hash_list = list()\n",
    "        # for every hash function\n",
    "        for i in range(1,201): ## change this to 51, 101 OR 201 for more hash functions!\n",
    "            random.seed(i+y) # call fixed seed. That way we will have the same a and b for all the same hash function accross users\n",
    "            a  = random.randint(1000, 10990) # create a variable\n",
    "            b  = random.randint(11000, 20000) # create b variable\n",
    "            min_value = 200000\n",
    "            # for every movie of the user \n",
    "            # calculate the min signature \n",
    "            for value in sets:\n",
    "                min_value = compute_min_value(a, value, b, R, min_value)\n",
    "            hash_list.append(min_value)\n",
    "        list_of_hashes.append(hash_list)  \n",
    "    list_of_5_dif_functions.append(list_of_hashes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7ac12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run the users 7 and 650 have similarity equal to: 0.52\n",
      "For the 1st run the users 112 and 772 have similarity equal to: 0.52\n",
      "For the 1st run the users 140 and 155 have similarity equal to: 0.54\n",
      "For the 1st run the users 151 and 716 have similarity equal to: 0.5\n",
      "For the 1st run the users 197 and 600 have similarity equal to: 0.54\n",
      "For the 1st run the users 197 and 826 have similarity equal to: 0.56\n",
      "For the 1st run the users 276 and 303 have similarity equal to: 0.51\n",
      "For the 1st run the users 328 and 788 have similarity equal to: 0.67\n",
      "For the 1st run the users 356 and 856 have similarity equal to: 0.62\n",
      "For the 1st run the users 362 and 772 have similarity equal to: 0.52\n",
      "For the 1st run the users 408 and 898 have similarity equal to: 0.81\n",
      "For the 1st run the users 416 and 450 have similarity equal to: 0.51\n",
      "For the 1st run the users 446 and 853 have similarity equal to: 0.51\n",
      "For the 1st run the users 451 and 489 have similarity equal to: 0.54\n",
      "For the 1st run the users 489 and 587 have similarity equal to: 0.66\n",
      "For the 1st run the users 551 and 682 have similarity equal to: 0.51\n",
      "For the 1st run the users 554 and 764 have similarity equal to: 0.51\n",
      "For the 1st run the users 600 and 826 have similarity equal to: 0.54\n",
      "For the 1st run the users 673 and 784 have similarity equal to: 0.5\n",
      "For the 1st run the users 674 and 879 have similarity equal to: 0.51\n",
      "For the 1st run the users 750 and 755 have similarity equal to: 0.51\n",
      "For the 1st run the users 750 and 853 have similarity equal to: 0.51\n"
     ]
    }
   ],
   "source": [
    "# calculate the y_pred. This will be used to calculate the False positive and False negative.\n",
    "# We do this for all functions.\n",
    "y_pred = list()\n",
    "y_pred_Second_function = list() \n",
    "y_pred_Third_function = list() \n",
    "y_pred_Fourth_function = list() \n",
    "y_pred_Fifth_function = list() \n",
    "for indexer in range(0,5):\n",
    "    # i and j moves throught the lists. For all the combinations of lists!\n",
    "    # values moves the values of the lists\n",
    "    for i, j in combinations(range(len(list_of_5_dif_functions[indexer])), 2): \n",
    "        counter = 0 \n",
    "        total_counter = 0 \n",
    "        ratio = 0\n",
    "        # when this loop ends, i will have passed thought the first combination of lists:\n",
    "        for values in range(len(list_of_5_dif_functions[indexer][i])): \n",
    "            total_counter = total_counter + 1\n",
    "            if list_of_5_dif_functions[indexer][i][values] == list_of_5_dif_functions[indexer][j][values]: \n",
    "                counter = counter + 1\n",
    "        ratio = counter/total_counter\n",
    "        ratio = round(ratio,2)\n",
    "        if ratio>= 0.5:\n",
    "            # i create the pairs that were found to have the same similarity\n",
    "            ## indexer enumerates throught the different lists. Each of the list is calculated with a different hash function\n",
    "            if indexer == 0:\n",
    "                merged_value = str(i) + '-' + str(j)\n",
    "                y_pred.append(merged_value)\n",
    "                print(f'For the 1st run the users {i+1} and {j+1} have similarity equal to: {ratio}')\n",
    "            elif indexer == 1: \n",
    "                merged_value_Second_function = str(i) + '-' + str(j) \n",
    "                y_pred_Second_function.append(merged_value_Second_function) \n",
    "            elif indexer == 2:\n",
    "                merged_value_Third_function = str(i) + '-' + str(j) \n",
    "                y_pred_Third_function.append(merged_value_Third_function) \n",
    "            elif indexer == 3:\n",
    "                merged_value_Fourth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fourth_function.append(merged_value_Fourth_function) \n",
    "            else:\n",
    "                merged_value_Fifth_function = str(i) + '-' + str(j) \n",
    "                y_pred_Fifth_function.append(merged_value_Fifth_function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca42869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1st run we found 13 false positives and 1 false negatives\n",
      "For 5 runs we found an average of 13.6 false positives and 1.6 false negatives\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "true_positives_Second_f = 0\n",
    "true_positives_Third_f = 0\n",
    "true_positives_Fourth_f = 0\n",
    "true_positives_Fifth_f = 0\n",
    "\n",
    "positive_predictions = len(y_pred)\n",
    "positve_actual = len(y_true)\n",
    "# for the values of the 'true' list\n",
    "for pairs_true in range(len(y_true)):\n",
    "    # for the values of the 'pred' list\n",
    "    for pairs_pred in range(len(y_pred)):\n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred[pairs_pred]:\n",
    "            true_positives = true_positives + 1\n",
    "    for pairs_pred in range(len(y_pred_Second_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Second_function[pairs_pred]:\n",
    "            true_positives_Second_f = true_positives_Second_f + 1         \n",
    "    for pairs_pred in range(len(y_pred_Third_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Third_function[pairs_pred]:\n",
    "            true_positives_Third_f = true_positives_Third_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fourth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fourth_function[pairs_pred]:\n",
    "            true_positives_Fourth_f = true_positives_Fourth_f + 1 \n",
    "    for pairs_pred in range(len(y_pred_Fifth_function)): \n",
    "        # Find the True Positives:\n",
    "        if y_true[pairs_true] == y_pred_Fifth_function[pairs_pred]:\n",
    "            true_positives_Fifth_f = true_positives_Fifth_f + 1 \n",
    "    \n",
    "    \n",
    "    \n",
    "               \n",
    "# calculating the False Positives:\n",
    "false_positives = positive_predictions - true_positives \n",
    "false_positives_Second_Function = positive_predictions - true_positives_Second_f\n",
    "false_positives_Third_Function = positive_predictions - true_positives_Third_f\n",
    "false_positives_Fourth_Function = positive_predictions - true_positives_Fourth_f\n",
    "false_positives_Fifth_Function = positive_predictions - true_positives_Fifth_f\n",
    "\n",
    "false_positives_avg = (false_positives+false_positives_Second_Function+false_positives_Third_Function+false_positives_Fourth_Function+false_positives_Fifth_Function)/5\n",
    "\n",
    "# calculating the False Negatives:\n",
    "false_negatives = positve_actual - true_positives \n",
    "false_negatives_Second_Function = positve_actual - true_positives_Second_f \n",
    "false_negatives_Third_Function = positve_actual - true_positives_Third_f \n",
    "false_negatives_Fourth_Function = positve_actual - true_positives_Fourth_f \n",
    "false_negatives_Fifth_Function = positve_actual - true_positives_Fifth_f \n",
    "\n",
    "false_negatives_avg = (false_negatives+false_negatives_Second_Function+false_negatives_Third_Function+false_negatives_Fourth_Function+false_negatives_Fifth_Function)/5\n",
    "\n",
    "print(f'For the 1st run we found {false_positives} false positives and {false_negatives} false negatives')\n",
    "print(f'For 5 runs we found an average of {false_positives_avg} false positives and {false_negatives_avg} false negatives')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "559d0f49",
   "metadata": {},
   "source": [
    "As we can see the more hash function we use the less are the false positives and false negatives. So, if we have many hash function and compute many min signatures we have more accurate results but we need more computing power and more time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38511d48",
   "metadata": {},
   "source": [
    "# 4) Locate similar users using LSH index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6db057e5",
   "metadata": {},
   "source": [
    "Firstly i create a function to split the list into bands as LSH commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "327835f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to split to bands and rows:\n",
    "def split_to_bands(signature, b):\n",
    "    assert len(signature) % b == 0\n",
    "    r = int(len(signature) / b)\n",
    "    \n",
    "    subvecs = []\n",
    "    for i in range(0,len(signature), r):\n",
    "        subvecs.append(signature[i : i+r])\n",
    "    return subvecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4d472a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to a list the lists of min signatures for the 5 different functions:\n",
    "lists_of_lists_of_hashes = list_of_5_dif_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6eb320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will store to a list of lists of lists the splited signatures of each user.\n",
    "# the big list contains the users with their splited signatures.\n",
    "# The big_big_list_... contains for the 5 different functions(runs) the splited min signatures for each user\n",
    "big_big_list_25 = list()\n",
    "big_big_list_40 = list()\n",
    "for lists in range(len(lists_of_lists_of_hashes)):\n",
    "    big_list_25 = list()\n",
    "    big_list_40 = list()\n",
    "    for list_of_lists in range(len(lists_of_lists_of_hashes[lists])):\n",
    "        splited_25 = split_to_bands(lists_of_lists_of_hashes[lists][list_of_lists], 25)\n",
    "        splited_40 = split_to_bands(lists_of_lists_of_hashes[lists][list_of_lists], 40)\n",
    "        big_list_25.append(splited_25)\n",
    "        big_list_40.append(splited_40)\n",
    "        \n",
    "    big_big_list_25.append(big_list_25)\n",
    "    big_big_list_40.append(big_list_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e23fb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LSH_sim_per_function_25 contains for the 5 different functions for 25 bands the similar candidates\n",
    "LSH_sim_per_function_25 = list()\n",
    "for lists in range(len(big_big_list_25)):\n",
    "    # we find the candidate similar pairs according to LSH method:\n",
    "    candidate_set_25 = set()\n",
    "    # for 25 bands:\n",
    "    # for combination of users:\n",
    "    for i, j in combinations(range(len(big_big_list_25[lists])), 2):\n",
    "        # for the bands of the combination of users:\n",
    "        for bands in range(len(big_big_list_25[lists][i])):\n",
    "            # if bands are equal then add users to the candidate set \n",
    "            if big_big_list_25[lists][i][bands] == big_big_list_25[lists][j][bands]:\n",
    "                candidate_set_25.add(str(i) + '-' + str(j))\n",
    "                break\n",
    "    LSH_sim_per_function_25.append(candidate_set_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bda16c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LSH_sim_per_function_40 contains for the 5 different functions for 40 bands the similar candidates\n",
    "LSH_sim_per_function_40 = list()\n",
    "for lists in range(len(big_big_list_40)):\n",
    "    # we find the candidate similar pairs according to LSH method:\n",
    "    candidate_set_40 = set()\n",
    "    # for 40 bands:\n",
    "    # for combination of users:\n",
    "    for i, j in combinations(range(len(big_big_list_40[lists])), 2):\n",
    "        # for the bands of the combination of users:\n",
    "        for bands in range(len(big_big_list_40[lists][i])):\n",
    "            # if bands are equal then add users to the candidate set \n",
    "            if big_big_list_40[lists][i][bands] == big_big_list_40[lists][j][bands]:\n",
    "                candidate_set_40.add(str(i) + '-' + str(j))\n",
    "                break \n",
    "    LSH_sim_per_function_40.append(candidate_set_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cfe162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the use of the first function for 200 hash functions and 25 bands we found 3 true positives\n",
      "with the use of the second function for 200 hash functions and 25 bands we found 2 true positives\n",
      "with the use of the third function for 200 hash functions and 25 bands we found 4 true positives\n",
      "with the use of the fourth function for 200 hash functions and 25 bands we found 4 true positives\n",
      "with the use of the fifth function for 200 hash functions and 25 bands we found 3 true positives\n",
      "the average true positives for 5 runs for 25 bands is 3.2\n"
     ]
    }
   ],
   "source": [
    "# this loops checks if the jaccard method and LSH method have found the same similar users.\n",
    "# for 25 bands:\n",
    "similars_per_function_25 = list()\n",
    "for functions in range(len(LSH_sim_per_function_25)):\n",
    "    count_25 = 0    \n",
    "    for values in range(len(y_true)):\n",
    "        for items in LSH_sim_per_function_25[functions]:\n",
    "            if items == y_true[values]:\n",
    "                count_25 = count_25 + 1    \n",
    "    similars_per_function_25.append(count_25)\n",
    "    \n",
    "print(f'with the use of the first function for 200 hash functions and 25 bands we found {similars_per_function_25[0]} true positives')\n",
    "print(f'with the use of the second function for 200 hash functions and 25 bands we found {similars_per_function_25[1]} true positives')\n",
    "print(f'with the use of the third function for 200 hash functions and 25 bands we found {similars_per_function_25[2]} true positives')\n",
    "print(f'with the use of the fourth function for 200 hash functions and 25 bands we found {similars_per_function_25[3]} true positives')\n",
    "print(f'with the use of the fifth function for 200 hash functions and 25 bands we found {similars_per_function_25[4]} true positives')\n",
    "\n",
    "average_true_positives_25 = sum(similars_per_function_25) / 5\n",
    "print(f'the average true positives for 5 runs for 25 bands is {average_true_positives_25}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8f00af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the use of the first function for 200 hash functions and 40 bands we found 7 true positives\n",
      "with the use of the second function for 200 hash functions and 40 bands we found 6 true positives\n",
      "with the use of the third function for 200 hash functions and 40 bands we found 6 true positives\n",
      "with the use of the fourth function for 200 hash functions and 40 bands we found 8 true positives\n",
      "with the use of the fifth function for 200 hash functions and 40 bands we found 10 true positives\n",
      "the average true positives for 5 runs for 40 bands is 7.4\n"
     ]
    }
   ],
   "source": [
    "# for 40 bands:\n",
    "similars_per_function_40 = list()\n",
    "for functions in range(len(LSH_sim_per_function_40)):\n",
    "    count_40 = 0\n",
    "    for values in range(len(y_true)):\n",
    "        for items in LSH_sim_per_function_40[functions]:\n",
    "            if items == y_true[values]:\n",
    "                count_40 = count_40 + 1\n",
    "    similars_per_function_40.append(count_40)\n",
    "\n",
    "print(f'with the use of the first function for 200 hash functions and 40 bands we found {similars_per_function_40[0]} true positives')\n",
    "print(f'with the use of the second function for 200 hash functions and 40 bands we found {similars_per_function_40[1]} true positives')\n",
    "print(f'with the use of the third function for 200 hash functions and 40 bands we found {similars_per_function_40[2]} true positives')\n",
    "print(f'with the use of the fourth function for 200 hash functions and 40 bands we found {similars_per_function_40[3]} true positives')\n",
    "print(f'with the use of the fifth function for 200 hash functions and 40 bands we found {similars_per_function_40[4]} true positives')\n",
    "\n",
    "average_true_positives_40 = sum(similars_per_function_40) / 5\n",
    "print(f'the average true positives for 5 runs for 40 bands is {average_true_positives_40}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126d3933",
   "metadata": {},
   "source": [
    "As we can see the larger the number of bands the better the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4e8065c",
   "metadata": {},
   "source": [
    "The number of evaluations performed are as many as the combination of users that were found to be candidate pairs by the LSH. This is the case, becasuse we compare the candidate pairs with the pairs that we got with the Jaccard method. With that being said for the first hash function there are 7 evaluations made."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aed59be",
   "metadata": {},
   "source": [
    "With the use of the Jaccard distance we have to compare 943*942/2 = 444,153 different pairs of users and find their similarity.\n",
    "One the other hand with the use of LSH we can make less comparisons since, if we find a band of a user to be equal to the same band of another user we can break the loop and make less comparisons. So, LSH is faster and needs less computing power to run because we can avoid comparing every pair."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fe9e196",
   "metadata": {},
   "source": [
    "Now, if we use 25 bands we find, an average of 3 true positives. We also know that according to jaccard similarity with a threshold of 0.5 we found 10 users to be similar. So, with the use of the LSH we are losing some pairs that according to Jaccard are similar. Maybe, if we tune the LSH we will find better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
